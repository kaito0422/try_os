Linux操作系统中的内存管理

Linux对于物理内存的管理都是以页page为单位的，使用struct page这个结构体来描述一个物理页的信息
struct page {
    unsigned long           flags;          // 标记是否为脏位；是否被锁定在内存中等
    atomic_t                _count;         // 该物理页被引用的次数，可根据此项决定该物理页是否可被替换
    atomic_t                _mapcount;
    unsigned long           private;
    struct address_space    *mapping;
    pgoff_t                 index;
    struct list_head        lru;
    void                    *virtual;
    ...
};
一般一个虚拟页会映射到一个物理页，即内存映射的最小单位是页（32位机上一般是4KB大小）。

根据物理页的功能不同，可以将物理页划分成区zone。Linux中的区分为3种
ZONE_DMA：该部分区域的物理页能够用于DMA传输数据（在x86上是指小于16MB的物理内存）
ZONE_NORMAL：该部分的物理页都是能够正常映射的页（在x86上范围在16~896MB之间的物理内存）
ZONE_HIGHMEM：高端内存，其中的物理页并不能永久映射到内核地址空间（在x86上是指大于896MB的物理内存）

ZONE_HIGHMEM：高端内存，在x86中指的是大于896MB的物理内存空间，内核不能直接使用这部分物理地址空间
对于高端内存的理解，参见 https://www.cnblogs.com/wuchanming/p/4756911.html
也可以查看本目录先的MemMan.pdf

struct zone {
    unsigned long           watermark[NR_WMARK];    // 该物理内存区域的最小值，最低水位，最高水位
    spinlock_t              lock;                   // 自旋锁，防止该结构被并发访问
    struct free_area        free_area[MAX_ORDER];   // MAX_ORDER默认为11，该数组用于存伙伴算法中的不同物理页数量的链表
    struct zone_lru {                               // 物理页替换LRU使用的链表，当物理页被访问过，就把该物理页对应的节点插到最前面，防止被替换
        struct list_head    list;
        unsigned long       nr_saved_scan;
    } lru[NR_LRU_LISTS];
    unsigned long           flags;
    const char              *name;                  // 用字符串表示该区域的名字
    ...
};

Linux中伙伴算法（用来申请获取比较大的物理内存，一般要大于一个页的大小）
在频繁地请求和释放不同大小的一组连续的物理页，必然会导致出现许多分散的小块的空闲页面，这就会导致命名可用内存的总大小超过请求需求，但是由于分散在不同
的地方，导致无法满足物理页的申请。
在用于描述物理区的结构体zone里面，有一个数组struct free_area free_area[MAX_ORDER]，该结构就是用于伙伴算法的。其中每一个元素也是一个结构体，其实现
如下：
struct free_area {
    struct list_head free_list; // 空闲页的双向链表
    unsigned long nr_free;      // 空闲页的数量
};
而free_area[k]表示一次分配物理页的数量为2^k个物理页对应的空闲链表。所以如果我们要分配2^k个物理页，就去zone中free_area数组的free_area[k]对应的链表
里面去寻找空闲的节点，分配出来使用；如果我们到free_area[k]对应的链表里面去找，发小没有空闲的节点了，则去free_area[k+1]的链表里面去找，然后进行分
割，将其中的一半用于当前内存申请，另一半挂到free_area[k]对应的链表上。
在释放物理页的时候，根据伙伴位图，判断释放的物理页是否需要进行内存合并（即存在伙伴关系），如果存在伙伴关系，则需要进行合并，再重新进行合并判断，一直
合并，直到不能合并为止（所以对于伙伴算法来说，一开始还是一整块大内存，通过不断的申请物理页来构建free_area链表）

Linux中的slab机制（用来频繁分配较小的内存，用于数据结构，达不到物理页那样的大小）
对于一种数据结构的大量分配释放，内核使用kmem_cache（高速缓存，和硬件上的cache不是一个东西）来表示；该kmem_cache内包含多个slab，有的slab满了（表示
里面所有可用的数据结构的对象都没分配使用了），有的slab是空的；对于一个slab，是一个链表，是预先分配好的需要的数据结构的可用对象。
当我们需要申请内存空间来存放一个数据结构时，就从slab里面去分配一个来使用，当释放的时候只是返还给slab，而不是真的释放。
这样做的好处就是避免频繁地使用malloc和free对应的系统调用，因为这两个内存分配相关的系统调用是最耗时的，通过slab机制可以快速构建数据结构对象，并且可以
避免产生内存碎片:)

虚拟内存（注意并不是虚拟地址）
起因：程序变得越来越大，且越来越多的程序同时在操作系统中运行，导致内存会被占满，以致不够用。因此，为了满足尽可能多的应用程序能够同时在系统环境下运
行，出现了虚拟内存的概念。就是需要实现，即使程序的进程地址空间没有完全加载入内存也可以执行；当访问没有加载到内存的部分时，就动态从磁盘去加载那部分程
序到内存中。
虚拟内存的基本思想是（来自现代操作系统一书）：每个程序拥有自己的地址空间，这个空间被分割成很多个块，每一个块称作一页或页面；每一页有连续的地址范围；
这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序；当程序引用到一部分在物理内存中的地址空间时，由硬件立即执行必要的映射；当程序引用
到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。
由程序产生的地址称为虚拟地址，他们构成了一个虚拟地址空间，这些从CPU发出来的地址并不是直接发送到系统总线上去访问内存，而是要经过一定的转换，从虚拟地
址到物理地址的转换。在软件编程的角度来看，就是程序出来的地址传给MMU（内存管理单元），MMU把虚拟地址转换成物理地址，然后用物理地址去访问内存。但是在微
架构层面，或者说硬件层面则不是这样的。硬件的MMU里面会有一个寄存器用来保存页表的基地址，当进程切换的时候，就需要更新这个寄存器的内容到新的进行的页表所
在的位置。其实在CPU和内存之间还存在多层级cache架构，L1 cache采用地址中的虚index位索引在cache的哪一个set里面，取出该set里面的所有cache line的
tags，与此同时，虚拟地址被传入一个叫TLB的地址进行索引，TLB里面是页表的缓存，访问速度比内存块很多，通过TLB中缓存的页表把虚拟地址转换成物理地址，把该
物理地址中的tag位域取出来和从cache中取出来的tags进行对比，如果有相同的，则表示cache命中，如果没有则表示cache缺失，会一级一级往下寻找，直到找到内
存。
但是这只是虚拟地址到物理地址的转换，对于操作系统来说，如果当前内存中每一个物理页都已经被进程使用，但是执行的进程还是访问到了一个还没有被载入到内存中
的进程虚拟页呢？（判断一个虚拟页是否加载到内存内，可以用页表中的一个标志位进行判断，标志位为1表示该虚拟页以及加载在内存中，标志位为0表示该虚拟页不在
内存中；同时页表的标志位还可以做其它标记，比如该页面是否被写过的脏位，可以用来替换页面时的写回策略等）则这时候就需要操作系统做点什么。
缺页中断（异常）处理：
    （1）硬件陷入内核，在栈中保存程序计数器以及其它通用寄存器的值（相当于是保护进程上下文，毕竟算是中断或异常）
    （2）查找当前进程到底需要哪一个虚拟页（一般硬件寄存器上会有记录，是在不行通过页表中的记录和当前产生异常的指令地址也能判断）
    （3）根据这个确实的虚拟页，检查是否是要为其服务
    （4）用页面替换算法选择一个在内存中已有的物理页作为牺牲页，如果牺牲页是被写过的（脏位被标记了），则需要把这一页写回磁盘，并发生上下文切换（因为使
    用磁盘驱动程序的时间代价较大）
    （5）一旦这个牺牲页可以使用后，就调用磁盘驱动程序把我们需要的虚拟页装载到这个牺牲页中，并发生上下文切换（再次调用磁盘，时间较长）
    （6）已经把需要的虚拟页装载到物理内存中了，这时候需要修改也表的映射关系（因为新加载进来的页物理地址没变，对应的虚拟地址变了，因此TLB也要改变）
    （7）异常返回，恢复上下文环境，重新执行之前导致缺页异常的指令







